---
markmap:
  colorFreezeLevel: 5
  maxWidth: 800
---
# NLP

## [Bahdanau attention](https://arxiv.org/abs/1409.0473)


## [Luong attention](https://arxiv.org/abs/1508.04025)


## [Transformer](https://arxiv.org/abs/1706.03762)

### [BERT](https://arxiv.org/abs/1810.04805)
- 성능 향상
  - [RoBERTa](https://arxiv.org/abs/1907.11692)
  - [Big Bird](https://arxiv.org/abs/2007.14062)
  - [XLNet](https://arxiv.org/abs/1906.08237)

- domain 적용
  - [BioBERT](https://arxiv.org/abs/1901.08746)
  - [LogBERT](https://arxiv.org/abs/2103.04475)

- 경량화
  - [DistilBERT](https://arxiv.org/abs/1910.01108)


### [GPT-1](https://openai.com/research/language-unsupervised)
- [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
  - [GPT-3](https://arxiv.org/abs/2005.14165)

### [BART](https://arxiv.org/abs/1910.13461)
- 성능 향상
  - [T5](https://arxiv.org/abs/1910.10683)
- multimodal
  - [METALM](https://arxiv.org/abs/2206.06336)



## Benchmark
### [GLUE](https://arxiv.org/abs/1804.07461)
- [SuperGLUE](https://arxiv.org/abs/1905.00537)

### [DecaNLP](https://arxiv.org/abs/1806.08730)

### [FEVER](https://arxiv.org/abs/1803.05355)